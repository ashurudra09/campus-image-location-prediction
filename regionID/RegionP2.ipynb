{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-20T17:28:37.197Z"
    },
    "id": "OHQuj0bjWS-O",
    "outputId": "59c06b50-654b-4a49-e28b-14caed2c3dad",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "labels_train=pd.read_csv(\"labels_train.csv\")\n",
    "labels_val=pd.read_csv(\"labels_val.csv\")\n",
    "print(labels_train.head())\n",
    "print(labels_val.head())\n",
    "# Print shape\n",
    "print(labels_train.shape)\n",
    "print(labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-20T17:28:37.198Z"
    },
    "id": "HM6izIfdaOWZ",
    "outputId": "748e1bb9-117d-4d96-b735-55cd9ed7c0d2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Boxplot of regionID\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=labels_train['Region_ID'])\n",
    "plt.title('RegionID Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-20T17:28:37.198Z"
    },
    "id": "sTFTndjqWEIc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# filename timestamp  latitude  longitude  angle  Region_ID\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class SMAIDataset(Dataset):\n",
    "    def __init__(self,preprocess_df,root_dir,transform=None):\n",
    "        self.preprocess_df=preprocess_df\n",
    "        self.root_dir=root_dir\n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.preprocess_df)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_name=os.path.join(self.root_dir,self.preprocess_df.iloc[idx,0])\n",
    "        image=Image.open(img_name)\n",
    "        region_id = torch.tensor(self.preprocess_df.iloc[idx, 5], dtype=torch.long)\n",
    "        if self.transform:\n",
    "            image=self.transform(image)\n",
    "        return image,region_id\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=10):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0 \n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            labels= labels - 1\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = 100 * correct / total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                labels = labels - 1\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_acc = 100 * correct / total\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {train_loss:.4f}, Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_region_model.pth\")\n",
    "            print(f\"Best model saved at epoch {epoch+1}\")\n",
    "\n",
    "        if optimizer.param_groups[0]['lr'] < 1e-6:\n",
    "            break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqgCmUGns8Dx"
   },
   "source": [
    "# Region Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-20T17:28:37.198Z"
    },
    "id": "Bd3NRjUDcFxG",
    "outputId": "700edfb2-2e4c-463d-81f4-5336556b372d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# Load pretrained weights & transform\n",
    "weights = ConvNeXt_Tiny_Weights.DEFAULT\n",
    "# transform = weights.transforms()\n",
    "transform=transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# Load model\n",
    "model = convnext_tiny(weights=weights,stochastic_depth_prob=0.5)\n",
    "num_features = model.classifier[2].in_features\n",
    "# 15 classes\n",
    "model.classifier[2] = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.LayerNorm(num_features,eps=1e-6),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(num_features, 15))\n",
    "model = model.to(device)\n",
    "\n",
    "# 5. Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "\n",
    "# Datasets\n",
    "train_dataset = SMAIDataset(labels_train, 'images_train', transform=transform)\n",
    "val_dataset = SMAIDataset(labels_val, 'images_val', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=1, factor=0.5)\n",
    "\n",
    "# Training\n",
    "print(\"Training for regionID\")\n",
    "model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=40)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
