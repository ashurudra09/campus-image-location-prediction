{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T09:50:55.480151Z",
     "iopub.status.busy": "2025-05-04T09:50:55.479423Z",
     "iopub.status.idle": "2025-05-04T09:50:57.011911Z",
     "shell.execute_reply": "2025-05-04T09:50:57.010913Z"
    },
    "id": "OHQuj0bjWS-O",
    "outputId": "e37f1962-49fe-4148-90a4-dbbe56424c3c",
    "papermill": {
     "duration": 1.548545,
     "end_time": "2025-05-04T09:50:57.013323",
     "exception": false,
     "start_time": "2025-05-04T09:50:55.464778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "labels_train=pd.read_csv(\"labels_train.csv\")\n",
    "labels_val=pd.read_csv(\"labels_val.csv\")\n",
    "print(labels_train.head())\n",
    "print(labels_val.head())\n",
    "# Print shape\n",
    "print(labels_train.shape)\n",
    "print(labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T09:50:57.042333Z",
     "iopub.status.busy": "2025-05-04T09:50:57.041780Z",
     "iopub.status.idle": "2025-05-04T09:50:58.986569Z",
     "shell.execute_reply": "2025-05-04T09:50:58.985776Z"
    },
    "id": "RDwFlaJLWVat",
    "outputId": "88afe417-01ee-44c6-83c5-078aaf10402e",
    "papermill": {
     "duration": 1.960183,
     "end_time": "2025-05-04T09:50:58.987677",
     "exception": false,
     "start_time": "2025-05-04T09:50:57.027494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# For latitude and longitude columns, print the distribution\n",
    "print(\"Latitude Distribution:\")\n",
    "print(labels_train['latitude'].describe())\n",
    "print(\"\\nLongitude Distribution:\")\n",
    "print(labels_train['longitude'].describe())\n",
    "\n",
    "# Boxplot for latitude and longitude\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=labels_train['latitude'])\n",
    "plt.title('Latitude Distribution')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=labels_train['longitude'])\n",
    "plt.title('Longitude Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T09:50:59.017443Z",
     "iopub.status.busy": "2025-05-04T09:50:59.017136Z",
     "iopub.status.idle": "2025-05-04T09:50:59.231039Z",
     "shell.execute_reply": "2025-05-04T09:50:59.230242Z"
    },
    "id": "qrKaJ605Ya-0",
    "outputId": "0c8a88f0-f767-4ae9-88ef-db8326065dd4",
    "papermill": {
     "duration": 0.229789,
     "end_time": "2025-05-04T09:50:59.232311",
     "exception": false,
     "start_time": "2025-05-04T09:50:59.002522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iqr_filter(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Apply IQR filtering on labels_train\n",
    "labels_train = iqr_filter(labels_train, 'latitude')\n",
    "labels_train = iqr_filter(labels_train, 'longitude')\n",
    "\n",
    "# Apply IQR filtering on labels_val\n",
    "labels_val = iqr_filter(labels_val, 'latitude')\n",
    "labels_val = iqr_filter(labels_val, 'longitude')\n",
    "# Now describe latitude and longitude again\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=labels_train['latitude'])\n",
    "plt.title('Latitude Distribution')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=labels_train['longitude'])\n",
    "plt.title('Longitude Distribution')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T09:50:59.263379Z",
     "iopub.status.busy": "2025-05-04T09:50:59.263136Z",
     "iopub.status.idle": "2025-05-04T09:50:59.417810Z",
     "shell.execute_reply": "2025-05-04T09:50:59.417266Z"
    },
    "id": "HM6izIfdaOWZ",
    "outputId": "49c72ef4-7d53-4d67-c069-21b7a019250a",
    "papermill": {
     "duration": 0.171361,
     "end_time": "2025-05-04T09:50:59.419113",
     "exception": false,
     "start_time": "2025-05-04T09:50:59.247752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Standardize latitude and longitude\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "latlong_scaler = RobustScaler()\n",
    "latlong_train = labels_train[['latitude', 'longitude']]\n",
    "latlong_val = labels_val[['latitude', 'longitude']]\n",
    "\n",
    "labels_train[['latitude', 'longitude']] = latlong_scaler.fit_transform(latlong_train)\n",
    "labels_val[['latitude', 'longitude']] = latlong_scaler.transform(latlong_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T09:50:59.451155Z",
     "iopub.status.busy": "2025-05-04T09:50:59.450900Z",
     "iopub.status.idle": "2025-05-04T09:50:59.455119Z",
     "shell.execute_reply": "2025-05-04T09:50:59.454333Z"
    },
    "id": "xGzpMnp5bA7n",
    "outputId": "f6e17931-e858-480b-d845-54b4e54f08a8",
    "papermill": {
     "duration": 0.021391,
     "end_time": "2025-05-04T09:50:59.456338",
     "exception": false,
     "start_time": "2025-05-04T09:50:59.434947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data is cleaned, now let's check the number of rows\n",
    "print(labels_train.shape)\n",
    "print(labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T09:50:59.485513Z",
     "iopub.status.busy": "2025-05-04T09:50:59.485320Z",
     "iopub.status.idle": "2025-05-04T09:51:09.563598Z",
     "shell.execute_reply": "2025-05-04T09:51:09.563004Z"
    },
    "id": "sTFTndjqWEIc",
    "papermill": {
     "duration": 10.094379,
     "end_time": "2025-05-04T09:51:09.564943",
     "exception": false,
     "start_time": "2025-05-04T09:50:59.470564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset\n",
    "class SMAIDataset(Dataset):\n",
    "    def __init__(self, preprocess_df, root_dir, transform=None):\n",
    "        self.preprocess_df = preprocess_df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.preprocess_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.preprocess_df.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        latitude = self.preprocess_df.iloc[idx, 2]\n",
    "        longitude = self.preprocess_df.iloc[idx, 3]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        labels = torch.tensor([latitude, longitude], dtype=torch.float32)\n",
    "        return image, labels\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=10):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, LR: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_latlong_model.pth\")\n",
    "            print(f\"Best model saved at epoch {epoch+1}\")\n",
    "        if optimizer.param_groups[0]['lr'] < 5e-6:\n",
    "            break\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqgCmUGns8Dx",
    "papermill": {
     "duration": 0.014164,
     "end_time": "2025-05-04T09:51:09.594292",
     "exception": false,
     "start_time": "2025-05-04T09:51:09.580128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Latitude-Longitude Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T09:51:09.624483Z",
     "iopub.status.busy": "2025-05-04T09:51:09.623751Z",
     "iopub.status.idle": "2025-05-04T10:53:25.267383Z",
     "shell.execute_reply": "2025-05-04T10:53:25.266706Z"
    },
    "id": "Bd3NRjUDcFxG",
    "outputId": "c232005f-7ce4-4b57-b974-dfa9969b2cf4",
    "papermill": {
     "duration": 3735.676804,
     "end_time": "2025-05-04T10:53:25.285424",
     "exception": false,
     "start_time": "2025-05-04T09:51:09.608620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load pretrained weights & transform\n",
    "weights = ConvNeXt_Tiny_Weights.DEFAULT\n",
    "# transform = weights.transforms()\n",
    "transform=transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "# Load model\n",
    "model = convnext_tiny(weights=weights,stochastic_depth_prob=0.5)\n",
    "num_features = model.classifier[2].in_features\n",
    "model.classifier=nn.Sequential(\n",
    "     nn.Flatten(),\n",
    "     nn.LayerNorm(num_features, eps=1e-6),\n",
    "     nn.Dropout(p=0.5),\n",
    "     nn.Linear(num_features,2)\n",
    "    )\n",
    "model = model.to(device)\n",
    "\n",
    "# Datasets\n",
    "train_dataset = SMAIDataset(labels_train, 'images_train', transform=transform)\n",
    "val_dataset = SMAIDataset(labels_val, 'images_val', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Loss, Optimizer, Scheduler\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=1, factor=0.5)\n",
    "\n",
    "# Training\n",
    "print(\"Training for latitude and longitude\")\n",
    "model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T10:53:25.319689Z",
     "iopub.status.busy": "2025-05-04T10:53:25.319066Z",
     "iopub.status.idle": "2025-05-04T10:53:28.426070Z",
     "shell.execute_reply": "2025-05-04T10:53:28.425358Z"
    },
    "id": "lKI-C7ajJvf-",
    "outputId": "1e57ea08-deba-4b8b-bbf1-5c5b9a081476",
    "papermill": {
     "duration": 3.125365,
     "end_time": "2025-05-04T10:53:28.427355",
     "exception": false,
     "start_time": "2025-05-04T10:53:25.301990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_outputs = []\n",
    "total_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images,labels) in enumerate(val_loader):\n",
    "        latitudes = labels[:, 0]\n",
    "        longitudes = labels[:, 1]\n",
    "        batch_start = i * val_loader.batch_size\n",
    "        images = images.to(device)\n",
    "\n",
    "        targets = torch.stack((latitudes, longitudes), dim=1)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Inverse transform\n",
    "        outputs_np = outputs.cpu().numpy()\n",
    "        targets_np = targets.numpy()\n",
    "\n",
    "        outputs_unscaled = latlong_scaler.inverse_transform(outputs_np)\n",
    "        targets_unscaled = latlong_scaler.inverse_transform(targets_np)\n",
    "\n",
    "        # Back to tensor\n",
    "        outputs_unscaled_tensor = torch.tensor(outputs_unscaled, dtype=torch.float32)\n",
    "        targets_unscaled_tensor = torch.tensor(targets_unscaled, dtype=torch.float32)\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(outputs_unscaled_tensor, targets_unscaled_tensor)\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "\n",
    "        # Add predictions with index as ID\n",
    "        for j, (lat, lon) in enumerate(outputs_unscaled):\n",
    "            all_outputs.append([batch_start + j, lat, lon])\n",
    "\n",
    "avg_loss = total_loss / len(val_loader.dataset)\n",
    "print(f\"Validation MSE: {avg_loss:.4f}\")\n",
    "\n",
    "# Save\n",
    "df = pd.DataFrame(all_outputs, columns=[\"id\", \"Latitude\", \"Longitude\"])\n",
    "df.to_csv(\"solution.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3790.81809,
   "end_time": "2025-05-04T10:53:31.303924",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-04T09:50:20.485834",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
